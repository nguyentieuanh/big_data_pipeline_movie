# ğŸ¬ Movie Big Data Analytics Platform

Há»‡ thá»‘ng thu tháº­p, lÆ°u trá»¯, vÃ  phÃ¢n tÃ­ch dá»¯ liá»‡u phim thá»i gian thá»±c (Real-time Movie Analytics Platform).
Dá»± Ã¡n Ä‘Æ°á»£c xÃ¢y dá»±ng dá»±a trÃªn kiáº¿n trÃºc **Lambda Architecture** sá»­ dá»¥ng cÃ¡c cÃ´ng nghá»‡ Big Data hiá»‡n Ä‘áº¡i.

## ğŸ— Kiáº¿n trÃºc Há»‡ thá»‘ng

```mermaid
graph LR
    subgraph "Data Sources"
        Upload[Upload Script] -->|JSON/CSV| MinIO
        Producer[Kafka Producer] -->|Ratings| Kafka
    end
    
    subgraph "Batch Layer"
        MinIO --> SparkBatch[Spark Batch Job]
        SparkBatch --> ES[Elasticsearch]
    end
    
    subgraph "Speed Layer"
        Kafka --> SparkStream[Spark Streaming Job]
        SparkStream --> Mongo[MongoDB]
    end
    
    subgraph "Serving Layer"
        ES --> Kibana[Kibana Dashboard]
        Mongo --> Streamlit[Streamlit App]
    end
```

## ğŸš€ CÃ i Ä‘áº·t & Triá»ƒn khai

### YÃªu cáº§u
- Kubernetes (Minikube / Docker Desktop)
- Python 3.8+
- Helm
- `kubectl`

### BÆ°á»›c 1: Khá»Ÿi táº¡o Háº¡ táº§ng Plugin
```bash
# Táº¡o namespace
kubectl apply -f kubernetes/namespace.yaml

# Deploy cÃ¡c dá»‹ch vá»¥ (MinIO, Kafka, MongoDB, ELK)
kubectl apply -f kubernetes/minio.yaml
kubectl apply -f kubernetes/kafka.yaml
kubectl apply -f kubernetes/mongodb.yaml
kubectl apply -f kubernetes/elk.yaml
```

### BÆ°á»›c 2: Setup Dá»¯ liá»‡u Batch
```bash
# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

# Upload dá»¯ liá»‡u phim máº«u vÃ o MinIO
python producers/upload_to_minio.py

# Submit Spark Batch Job (Giáº£ Ä‘á»‹nh mÃ´i trÆ°á»ng Ä‘Ã£ cÃ³ spark-submit hoáº·c dÃ¹ng Spark Operator)
# spark-submit spark_jobs/batch/batch_etl.py
```

### BÆ°á»›c 3: Setup Dá»¯ liá»‡u Streaming
```bash
# Cháº¡y Kafka Producer (giáº£ láº­p rating)
python producers/kafka_producer.py
```

```bash
# Cháº¡y Spark Streaming Job (Terminal khÃ¡c)
# spark-submit --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.1.2,org.mongodb.spark:mongo-spark-connector_2.12:3.0.1 spark_jobs/stream/stream_processing.py
```

### BÆ°á»›c 4: Xem Dashboard
```bash
# Cháº¡y á»©ng dá»¥ng Streamlit
streamlit run dashboard/app.py
```

## ğŸ“‚ Cáº¥u trÃºc ThÆ° má»¥c
- `kubernetes/`: CÃ¡c file deployment K8s.
- `producers/`: Script sinh dá»¯ liá»‡u giáº£ láº­p.
- `spark_jobs/`: Source code xá»­ lÃ½ dá»¯ liá»‡u Spark (Batch & Streaming).
- `dashboard/`: MÃ£ nguá»“n á»©ng dá»¥ng hiá»ƒn thá»‹ Streamlit.

## ğŸ“ LiÃªn há»‡
[TÃªn cá»§a báº¡n] - Big Data Project
